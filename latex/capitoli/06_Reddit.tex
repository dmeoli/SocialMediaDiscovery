\chapter{Reddit}

\href{https://www.reddit.com/}{Reddit} {\`e} un aggregatore di social news nonch{\'e} sito internet di discussione e valutazione di contenuti web. Gli utenti registrati, chiamati redditors, possono pubblicare contenuti sotto forma di link o messaggi di testo che possono essere soggetti a commenti e a voti favorevoli o contrari da parte di altri membri, il che determina posizione e visibilit{\`a} dei vari contenuti sulle pagine del sito. Tali contenuti, chiamati discussions, vengono organizzati per argomenti in aree di interesse chiamate subreddits che coprono una variet{\`a} di argomenti tra cui istruzione, intrattenimento, humor, tecnologia, ecc..

\begin{figure}\centering
\includegraphics[scale=0.15]{img/reddit}
\caption{Logo di Reddit.}
\end{figure}

\subsection{Datasets}

I datasets mensili di Reddit, resi disonibili online in formato JSON dal author \href{https://www.reddit.com/users/Stuck_In_the_Matrix/}{u/Stuck\_In\_the\_Matrix} e suddivisi in \href{https://files.pushshift.io/reddit/discussions/}{discussions} (10 mln ca.) e \href{https://files.pushshift.io/reddit/comments/}{commenti} (80 mln ca.), sono stati importati all'interno di \href{https://www.mongodb.com/it}{MongoDB}, un DBMS\footnote{Database Management System} NoSQL orientato ai documenti, che ha permesso, per mezzo di indici di ricerca, una gestione pi{\`u} efficiente dei dati nei passi che verranno descritti in seguito.

\begin{figure}\centering
\includegraphics[scale=0.175]{img/mongo}
\caption{Logo di MongoDB.}
\end{figure}

\section{Filtraggio}

Per poter ridurre la dimensione dei dati in input ed allo stesso tempo dare un senso allo studio di cui parleremo in seguito, {\`e} stato effettuato un filtraggio per mezzo di alcuni criteri descritti nei paragrafi seguenti. A partire da quelle che sono le entit{\`a} del dominio applicativo in questione ci assicuriamo quindi di lavorare su un dataset formato da utenti particolarmente attivi e da discussions e commenti semanticamente significativi.

\subsection{Criteri}

\paragraph{Submissions}
Vengono considerati soltanto i discussions per cui:

\begin{enumerate}[label=(\roman*)]

\item
il numero di commenti {\`e} maggiore rispetto alla media, ossia:

\begin{equation}
\label{eq:1.1}
\text{\# commenti}>\frac{\text{\# commenti}}{\text{\# discussions}}
\end{equation}

\item
la lunghezza del selftext {\`e} maggiore rispetto alla media, ossia:

\begin{equation}
\label{eq:1.2}
\text{length(selftext)}>\frac{\sum_{s=1}^{\text{\# discussions}} \text{length(selftext(s))}}{\text{\# discussions}}
\end{equation}

\end{enumerate}

\paragraph{Commenti}
Vengono considerati soltanto i commenti per cui la lunghezza del body {\`e} maggiore rispetto alla media, ossia:

\begin{equation}
\text{length(body)}>\frac{\sum_{c=1}^{\text{\# commenti}} \text{length(body(c))}}{\text{\# commenti}}
\end{equation}

\paragraph{Redditors}
Vengono considerati soltanto i discussions ed i commenti scritti dai redditors in numero maggiore rispetto alla media, ossia:

\begin{equation}
\text{\# discussions + \# commenti}>\frac{\text{\# discussions + \# commenti}}{\text{\# distinti utenti}}
\end{equation}

\paragraph{Subreddits}
Vengono considerati soltanto i subreddits per cui il numero di discussions appartenenti, in seguito al filtraggio definito dai criteri \eqref{eq:1.1} e \eqref{eq:1.2}, risulti maggiore rispetto alla media, ossia:

\begin{equation}
\text{\# discussions filtrati}>\frac{\text{\# discussions}}{\text{\# distinti subreddit}}
\end{equation}

In riferimento al dataset Reddit di Novembre 2017, ad esempio, i criteri appena definiti hanno prodotto un filtraggio dei dati come segue. Vengono considerati:

\begin{enumerate}[label=(\roman*)]

\item 
i \textit{discussions} per cui il numero di commenti {\`e} maggiore di 8 e per cui la lunghezza del selftext {\`e} maggiore di 168 caratteri;

\item
i \textit{commenti} per cui la lunghezza del body {\`e} maggiore di 170 caratteri;

\item 
i discussions ed i commenti che i \textit{redditors} autori hanno scritto in numero maggiore di 20;

\item
i \textit{subreddits} per cui il numero di discussions che vi appartengono, in seguito al filtraggio, {\`e} maggiore di 77.

\end{enumerate}

I dati sono stati modellati optando per una rappresentazione ad albero dei subreddits che rispecchiasse la struttura del dominio applicativo dovuta alla possibilit{\`a} di interazioni multi-threading tra i redditors sotto un determinato submission. In dettaglio: un documento della nuova collezione rappresenta un subreddit con relativo id e nome. Ogni subreddit contiene una lista di discussions che, a loro volta, possono contenere una lista di commenti. Ogni submission e/o commento contiene un id, l'autore, la data e l'ora della pubblicazione ed il risultato della fase di NLP sul corpo testuale. Ogni submission contiene una lista di similarit{\`a} lessicali e semantiche calcolate come definito nelle sezioni precedenti ed ogni commento pu{\`o} a sua volta contenere un'altra lista di commenti con gli stessi campi e cos{\`i} via per oguno di essi.

\newpage

\lstinputlisting[language=json, caption={Esempio di JSON Subreddit}, captionpos=b]{sample.json}

A partire da oggetti Java creati per mezzo di classi modellate opportunamente per poter rappresentare le entit{\`a} del social media Reddit cos{\`i} come sopra descritte, {\`e} stato possibile, grazie alle \href{https://github.com/google/gson}{API Gson} di Google, convertire tali oggetti in documenti JSON che sono poi stati serializzati all'interno di una nuova collezione di MongoDB. 